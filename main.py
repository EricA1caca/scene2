import os
from openai import OpenAI
from PIL import Image
import pytesseract
import requests

# è®¾ç½® Tesseract çš„å®‰è£…è·¯å¾„ï¼ˆWindows éœ€è¦ï¼‰
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key="75aaa5837e148b567ba15405e9a5422f97c1d0b6",  # æ›¿æ¢ä¸ºä½ çš„æ˜Ÿæ²³å¤§æ¨¡å‹ API Key
    base_url="https://aistudio.baidu.com/llm/lmapi/v3"  # æ˜Ÿæ²³å¤§æ¨¡å‹çš„ API åŸŸå
)

def extract_text_from_image(image_path):
    """
    ä½¿ç”¨ OCR ä»å›¾ç‰‡ä¸­æå–æ–‡å­—
    """
    try:
        # æ‰“å¼€å›¾ç‰‡
        image = Image.open(image_path)
        # ä½¿ç”¨ pytesseract æå–æ–‡å­—
        text = pytesseract.image_to_string(image, lang='chi_sim')  # ä¸­æ–‡è¯†åˆ«
        return text.strip()  # å»é™¤ç©ºç™½å­—ç¬¦
    except Exception as e:
        return None  # å¦‚æœæå–å¤±è´¥ï¼Œè¿”å› None

def describe_image(image_path):
    """
    ä½¿ç”¨ç™¾åº¦å›¾åƒæè¿° API æè¿°å›¾ç‰‡å†…å®¹
    """
    # ç™¾åº¦å›¾åƒæè¿° API çš„ URL å’Œ API Key
    api_url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/image_classify/image_description"
    access_token = "75aaa5837e148b567ba15405e9a5422f97c1d0b6"  # æ›¿æ¢ä¸ºä½ çš„ç™¾åº¦ Access Token

    # è¯»å–å›¾ç‰‡
    with open(image_path, "rb") as image_file:
        image_data = image_file.read()

    # å‘é€è¯·æ±‚
    headers = {"Content-Type": "application/json"}
    params = {"access_token": access_token}
    response = requests.post(api_url, headers=headers, params=params, data=image_data)

    # è§£æå“åº”
    if response.status_code == 200:
        result = response.json()
        return result.get("result", {}).get("description", "æ— æ³•æè¿°å›¾ç‰‡å†…å®¹")
    else:
        return f"æè¿°å›¾ç‰‡æ—¶å‡ºé”™ï¼š{response.status_code}, {response.text}"

def deepseek_generate(prompt):
    """
    ä½¿ç”¨ DeepSeek ç”Ÿæˆæ–‡æœ¬
    """
    try:
        response = client.chat.completions.create(
            model="ernie-3.5-8k",  # æ›¿æ¢ä¸ºæ”¯æŒçš„æ¨¡å‹åç§°
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200  # æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ç”Ÿæˆæ–‡æœ¬æ—¶å‡ºé”™ï¼š{e}"

def generate_advertisement(image_path):
    """
    æ ¹æ®å›¾ç‰‡å†…å®¹ç”Ÿæˆå¹¿å‘Šæ–‡æ¡ˆ
    """
    # æå–å›¾ç‰‡ä¸­çš„æ–‡å­—
    image_text = extract_text_from_image(image_path)

    # å¦‚æœå›¾ç‰‡ä¸­æ²¡æœ‰æ–‡å­—ï¼Œæè¿°å›¾ç‰‡å†…å®¹
    if not image_text:
        print("å›¾ç‰‡ä¸­æ²¡æœ‰æ–‡å­—ï¼Œæ­£åœ¨æè¿°å›¾ç‰‡å†…å®¹...")
        image_text = describe_image(image_path)

    # ç”Ÿæˆå¹¿å‘Šæ–‡æ¡ˆ
    text_prompt = f"è¯·æ ¹æ®ä»¥ä¸‹å›¾ç‰‡å†…å®¹ç”Ÿæˆä¸€æ®µå¹¿å‘Šæ–‡æ¡ˆï¼š{image_text}"
    ad_text = deepseek_generate(text_prompt)

    return f"ğŸ–¼ï¸ å›¾ç‰‡å†…å®¹ï¼š{image_text}\nğŸ“¢ å¹¿å‘Šæ–‡æ¡ˆï¼š{ad_text}"

def process_folder(folder_path):
    """
    å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡å¹¶ç”Ÿæˆå¹¿å‘Šæ–‡æ¡ˆ
    """
    # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(folder_path):
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå›¾ç‰‡
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
            image_path = os.path.join(folder_path, filename)
            print(f"å¤„ç†å›¾ç‰‡: {filename}")
            print(generate_advertisement(image_path))
            print("-" * 50)

# å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡
folder_path = "D:/model/input"  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶å¤¹è·¯å¾„
process_folder(folder_path)